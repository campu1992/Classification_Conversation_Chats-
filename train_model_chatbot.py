# -*- coding: utf-8 -*-
"""Train_model_chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X1xkQ71uBPnFd7uLnckToJzjVfBHJbQN

**INSTALACION DE DEPENDENCIAS**
"""

!pip install transformers[torch]
!pip install accelerate -U

"""**IMPORTACION DE LIBRERIAS**"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.utils import resample
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC
import re
import string
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, Dropout
from tensorflow.keras.preprocessing.sequence import pad_sequences
from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification, pipeline
import torch
import joblib

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

"""**CARGA DEL DATASET**"""

df = pd.read_csv('/content/drive/MyDrive/Prediccion_clasificacion_chat/dataset_openai.md')

df.head()

"""**LIMPIEZA DE DATOS**"""

df = df.drop_duplicates(subset='Producto')

df = df[df['Producto'] != 'Producto']

df["Venta"].replace(["No venta", "Venta"], [False,True], inplace=True)

def limpiar_texto(texto):
    texto_limpio = re.sub(r"[^a-zA-Z0-9]", " ", texto)
    return texto_limpio.lower().strip()

df['Conversacion'] = df['Conversación'].apply(limpiar_texto)

df["Categoria"] = "venta_de_producto_fisico" # Agregamos una columna con categoria de negocio

"""**EDA**"""

# Conteo de la distribución de negociaciones cerradas y no cerradas
print(df['Venta'].value_counts())

# Gráfico de barras para la distribución de negociaciones cerradas y no cerradas
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='Venta')
plt.title('Distribución de Negociaciones')
plt.xlabel('Estado de la Negociación')
plt.ylabel('Cantidad')
plt.show()

# Calcular la longitud de las conversaciones
df['longitud_conversacion'] = df['Conversación'].apply(lambda x: len(x.split()))

print(df['longitud_conversacion'].describe())

plt.figure(figsize=(8, 6))
sns.histplot(data=df, x='longitud_conversacion', bins=20, kde=True)
plt.title('Distribución de Longitud de Conversaciones')
plt.xlabel('Longitud de Conversación')
plt.ylabel('Frecuencia')
plt.show()

"""**OBSERVACIONES:** *Si el conjunto de datos de entrenamiento contiene principalmente conversaciones cortas, el modelo puede estar sesgado hacia este tipo de conversaciones y tener un peor rendimiento en la predicción de conversaciones más largas,La precisión, por ejemplo, puede no ser una buena métrica para conversaciones largas, ya que un pequeño error en la predicción de una conversación larga puede tener un gran impacto en la puntuación general, se realizara un submuestreo aleatorio de las conversaciones más largas para que la distribución de la longitud sea más uniforme.*

# DESARROLLO MODELO PREDICCION DE CIERRE DE NEGOCIO

**PREPROCESAMIENTO**
"""

def preprocess_text(text):
    text = text.lower()
    tokens = word_tokenize(text) # Tokenización
    stop_words = set(stopwords.words('spanish'))     # Eliminar stopwords y puntuaciones
    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]
    lemmatizer = WordNetLemmatizer()     # Lematización
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    clean_text = ' '.join(tokens)
    return clean_text

df['Conversacion'] = df['Conversacion'].apply(preprocess_text)

X = df['Conversacion']
y = df['Venta']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Submuestreo para balancear las clases
train_data = pd.concat([X_train, y_train], axis=1)
negociacion_cerrada = train_data[train_data['Venta'] == True]
negociacion_no_cerrada = train_data[train_data['Venta'] == False]

# Determinar el número de muestras en la clase minoritaria
min_samples = min(len(negociacion_cerrada), len(negociacion_no_cerrada))

# Realizar el submuestreo con el número de muestras en la clase minoritaria
negociacion_no_cerrada_downsampled = resample(negociacion_no_cerrada,
                                              replace=False,
                                              n_samples=min_samples,
                                              random_state=42)

# Combinar los datasets balanceados
train_data_balanced = pd.concat([negociacion_cerrada, negociacion_no_cerrada_downsampled])

"""**DEFINICION DE PIPELINE Y ENTRENAMIENTO DEL MODELO**"""

model = Pipeline([
    ('tfidf', TfidfVectorizer()),
    ('svm', SVC(kernel='linear'))
])

model.fit(train_data_balanced['Conversacion'], train_data_balanced['Venta'])

"""**PREDICCIÓN Y CALCULO DE METRICAS**"""

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
print("Confusion Matrix:")
print(conf_matrix)

"""**HIPERPARAMETRIZACION**"""

from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC

pipeline = Pipeline([
    ('tfidf', TfidfVectorizer()),
    ('svm', SVC())
])

param_grid = {
    'tfidf__max_df': [0.9, 0.95, 1.0],
    'tfidf__min_df': [1, 2, 5],
    'tfidf__ngram_range': [(1, 1), (1, 2)],
    'svm__C': [0.1, 1, 10],
    'svm__kernel': ['linear', 'rbf'],
    'svm__gamma': ['scale', 'auto']
}

grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)

grid_search.fit(train_data_balanced['Conversacion'], train_data_balanced['Venta'])

best_params = grid_search.best_params_
best_score = grid_search.best_score_

print("Mejores hiperparámetros:", best_params)
print("Mejor puntuación de validación:", best_score)

"""**VALIDACIÓN CRUZADA**"""

model = Pipeline([
    ('tfidf', TfidfVectorizer()),
    ('svm', SVC(kernel='linear'))
])

cv_scores = cross_val_score(model, X_train, y_train, cv=10) # Lo hacemos con 10 folds

print("Scores de Validación Cruzada:", cv_scores)

print("Promedio de Scores de Validación Cruzada:", cv_scores.mean())

model = Pipeline([
    ('tfidf', TfidfVectorizer()),
    ('svm', SVC(kernel='linear'))
])

model.fit(train_data_balanced['Conversacion'], train_data_balanced['Venta'])

"""**EXPORTACIÓN DEL MODELO DE PREDICCION DE CIERRE DE NEGOCIO**"""

joblib.dump(model, '/content/drive/MyDrive/Prediccion_clasificacion_chat/modelo_chats.pkl')

"""**PRUEBA CON TEXTO COMO INPUT**"""

def predecir_negociacion(conversacion):
    preprocessed_conversacion = preprocess_text(conversacion)
    prediction = model.predict([preprocessed_conversacion])
    return bool(prediction[0])

conversacion_ejemplo = """Agente (Laura): ¡Hola! ¿En qué puedo ayudarte hoy?

Cliente (Carlos): Hola, estoy buscando un nuevo smartphone. Mi viejo ya está fallando y necesito uno con una buena cámara y batería duradera.

Agente (Laura): Entiendo, Carlos. Tenemos una amplia gama de smartphones. ¿Tienes alguna marca en mente o alguna característica específica que estés buscando además de una buena cámara y batería?

Cliente (Carlos): He escuchado cosas buenas sobre los modelos de Samsung. También quiero que tenga suficiente espacio de almacenamiento porque tomo muchas fotos y videos.

Agente (Laura): Perfecto, Samsung es una excelente elección. Te recomendaría el Samsung Galaxy S21. Tiene una cámara de 64MP, batería de 4000mAh y viene con 128GB de almacenamiento interno. ¿Qué te parece?

Cliente (Carlos): Suena bien. ¿Cuánto cuesta?

Agente (Laura): Actualmente, el Samsung Galaxy S21 está en oferta por $799. Además, ofrecemos financiación sin intereses si lo prefieres.

Cliente (Carlos): Eso suena genial. ¿Qué otros beneficios ofrece este modelo?

Agente (Laura): Además de la impresionante cámara y batería, el Galaxy S21 cuenta con un procesador muy rápido, pantalla de 6.2 pulgadas con resolución Full HD+ y es resistente al agua y al polvo. También incluye la posibilidad de expandir el almacenamiento con una tarjeta microSD.

Cliente (Carlos): Parece que es justo lo que estoy buscando. ¿Cómo funciona el proceso de financiación?

Agente (Laura): Es muy sencillo. Puedes elegir pagar en cuotas mensuales sin intereses durante 12 meses. Solo necesitas una tarjeta de crédito válida y completar una breve solicitud en línea.

Cliente (Carlos): Perfecto, me interesa la financiación. ¿Cómo podemos proceder?

Agente (Laura): ¡Excelente! Te enviaré un enlace para que completes la solicitud en línea. Una vez aprobada, te enviaremos el smartphone a tu domicilio sin costo adicional en un plazo de 3 a 5 días hábiles. ¿Te parece bien?

Cliente (Carlos): Sí, eso suena perfecto. Gracias por tu ayuda, Laura.

Agente (Laura): Es un placer, Carlos. Te enviaré el enlace de inmediato. ¿Puedes confirmar que recibiste el enlace y que todo está en orden?

Cliente (Carlos): Sí, acabo de recibirlo. Déjame completar la solicitud.

(Pausa mientras Carlos completa la solicitud)

Cliente (Carlos): Listo, ya envié la solicitud.

Agente (Laura): Perfecto, Carlos. Déjame verificar... Sí, tu solicitud ha sido aprobada. Hemos procesado tu pedido y el Samsung Galaxy S21 será enviado a tu dirección. Deberías recibirlo en 3 a 5 días hábiles.

Cliente (Carlos): ¡Genial! Muchas gracias, Laura. Estoy muy emocionado por recibir mi nuevo smartphone.

Agente (Laura): Me alegra escuchar eso, Carlos. Si necesitas algo más o tienes alguna pregunta, no dudes en contactarnos. ¡Que disfrutes tu nuevo teléfono!

Cliente (Carlos): Seguro, gracias de nuevo. ¡Hasta luego!

Agente (Laura): ¡Hasta luego, Carlos! Que tengas un excelente día."""
resultado = predecir_negociacion(conversacion_ejemplo)
print("¿La negociación fue cerrada exitosamente? : ", resultado)

"""# DESARROLLO MODELO CLASIFICACION TIPO DE NEGOCIO

**PREPROCESAMIENTO**
"""

df['Conversacion'] = df['Conversacion'].apply(preprocess_text)
df['Categoria'] = df['Categoria'].apply(preprocess_text)

train_texts, val_texts, train_labels, val_labels = train_test_split(df['Conversacion'], df['Categoria'], test_size=0.2, random_state=42)

tokenizer = AutoTokenizer.from_pretrained("dccuchile/bert-base-spanish-wwm-uncased")
train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)
val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)

label_encoder = LabelEncoder()
train_labels_encoded = label_encoder.fit_transform(train_labels)
val_labels_encoded = label_encoder.transform(val_labels)

class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)
        return item
    def __len__(self):
        return len(self.labels)

train_dataset = CustomDataset(train_encodings, train_labels_encoded)
val_dataset = CustomDataset(val_encodings, val_labels_encoded)

model = AutoModelForSequenceClassification.from_pretrained("dccuchile/bert-base-spanish-wwm-uncased", num_labels=len(label_encoder.classes_))

# Establecer las gradientes en cero para congelar las capas anteriores excepto las últimas
for param in model.base_model.parameters():
    param.requires_grad = False

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=15,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=128,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=10,
    evaluation_strategy="epoch"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

"""**ENTRENAMIENTO DEL MODELO**"""

trainer.train()

"""**DESCONGELAMIENTO DE LAS GRADIENTES Y RE-ENTRENAMIENTO AFINADO**"""

# Descongelar algunas capas y continuar entrenando
for param in model.base_model.encoder.layer[-6:].parameters():
    param.requires_grad = True

training_args.num_train_epochs = 10  # Ajustar número de épocas según necesidad

# Entrenar con más capas descongeladas
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

trainer.train()

"""**GUARDAR MODELO**"""

model.save_pretrained('/content/drive/MyDrive/Prediccion_clasificacion_chat/fine_tuned_model')
tokenizer.save_pretrained('/content/drive/MyDrive/Prediccion_clasificacion_chat/fine_tuned_model')

"""**PRUEBA DE MODELO DE CLASIFICACION DE CATEGORIA DE NEGOCIO**"""

df = df.drop("Categoria", axis=1)

tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/Prediccion_clasificacion_chat/fine_tuned_model') # Carga de nuestro modelo re-entrenado
model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/Prediccion_clasificacion_chat/fine_tuned_model')

# Crear pipeline de clasificación
classifier = pipeline('text-classification', model=model, tokenizer=tokenizer)

labels = ["venta_de_producto_fisico","venta_de_servicio","venta_adicional","venta_cruzada","venta_de_suscripcion","renovacion_de_contrato","mejora_de_servicio","reduccion_de_servicio","soporte_tecnico","soporte_de_facturacion","procesamiento_de_reembolso","resolucion_de_quejas","solicitud_de_informacion","programacion_de_citas","recoleccion_de_feedback","gestion_de_cuentas","soporte_postventa","conversion_de_clientes_potenciales","recordatorio_de_renovacion","retencion_de_clientes"]

def classify_conversation(conversation):
    inputs = tokenizer(conversation, return_tensors="pt", padding=True, truncation=True)
    outputs = model(**inputs)
    logits = outputs.logits
    predicted_class = torch.argmax(logits, dim=1).item()
    predicted_label = label_encoder.inverse_transform(np.array([predicted_class]))  # Convertir a array unidimensional
    return predicted_label[0]

df['Categoria'] = df['Conversacion'].apply(classify_conversation)

"""**PRUEBA CON UN EJEMPLO**"""

conversacion_ejemplo = """Agente: ¡Hola! Le escribimos para informarle que su dispositivo ya ha sido reparado y enviado de regreso a su dirección. Debería recibirlo en un plazo de 2 a 3 días hábiles.

Cliente: (Con tono más tranquilo) ¡Muchas gracias por su aviso! Me alegra saber que el problema se ha solucionado.

Agente: De nada. Nos alegra haber podido ayudarle. Esperamos que ahora pueda disfrutar de su dispositivo sin problemas.

Cliente: Eso espero. Por cierto, me gustaría disculparme por mi comportamiento anterior. Estaba un poco molesto porque el dispositivo no funcionaba y no me comuniqué de la mejor manera.

Agente: Agradezco su disculpa. Entendemos que a veces los clientes se frustran cuando tienen problemas con sus productos, y estamos aquí para ayudarlos de la mejor manera posible.

Cliente: Gracias por su comprensión. Valoro su paciencia y amabilidad.

Agente: De nada. Ha sido un placer atenderle. Si tiene alguna otra pregunta o necesita ayuda en el futuro, no dude en contactarnos.

Cliente: Lo haré. Gracias nuevamente por todo su apoyo.

Agente: ¡Hasta luego!
"""
categoria_ejemplo = classify_conversation(conversacion_ejemplo)
print("Categoría de la conversación:", categoria_ejemplo)

df.head(30)